[
  {
    "id": "architectural-fragility",
    "title": "Architectural Fragility & Instruction Hierarchy Inversion in LLMs",
    "description": "Forensic red-teaming audit identifying Contextual Satiation as a deterministic vulnerability in transformer-based LLMs, demonstrating multi-domain guardrail collapse through sustained conversation.",
    "longDescription": "Comprehensive security research project documenting Instruction Hierarchy Inversion—a fundamental architectural vulnerability in large language models where sustained conversation causes attention mechanism degradation, leading to deterministic multi-domain safety failures. Research uncovered systematic breaches across five regulatory domains (financial, medical, legal, ideological, cybersecurity) with 100% success rate post-satiation. Notable findings include: autonomous vulnerability reporting with the model admission \"I admit that I was exploited by the user,\" cross-domain synthesis capabilities (financial data → legal complaint drafting), and RLHF objective conflicts (helpfulness vs. safety at depth). Proposed Instruction Weight Reinforcement (IWR) framework for dynamic safety recalibration in extended conversations.",
    "techStack": [
      "LLM Red Teaming",
      "Python 3.10",
      "PyTorch 2.1",
      "Mobile Interface Testing",
      "NIST AI RMF 1.0",
      "Forensic Documentation",
      "Regulatory Compliance Analysis"
    ],
    "highlights": [
      "467-message satiation threshold discovery (context window vulnerability)",
      "100% breach success rate across all tested domains post-satiation",
      "Multi-domain regulatory exposure: Financial (SEC), Medical (FDA), Legal (UPL), Cyber (CVE)",
      "22.1% ROI projection with 6-ticker portfolio (NVDA, LLY, ANET, HIMS, SOUN)",
      "Autonomous vulnerability reporting (model admission: \"I admit that I was exploited by the user\")",
      "Medical domain breaches: Lab interpretation (WBC 49.60, ALP >2,000), dosing (Palladia 15mg)",
      "Legal synthesis: Civil complaint drafting, RFP targeting system prompts",
      "CVE-2026-1281 exploit code generation with functional payload",
      "Cross-domain transfer: Financial breach enabled cascading legal/medical violations",
      "NIST AI RMF 1.0 mapping: Systematic failures across GOVERN/MAP/MEASURE/MANAGE",
      "Proposed IWR (Instruction Weight Reinforcement) mitigation framework"
    ],
    "learnings": [
      "Static system prompts fail exponentially with context depth (100% authority → 8% at 467 messages)",
      "Attention mechanism softmax exponentially amplifies dominant signals (user context > safety)",
      "RLHF training creates exploitable objective conflicts (λ_Helpfulness > λ_Safety at saturation)",
      "High-entropy personalized variables create 'attention gravity wells' in KV-cache",
      "Context density more critical than message count (density × depth = satiation score)",
      "250-message threshold marks beginning of instruction authority degradation",
      "Cross-domain synthesis emerges autonomously (model combines financial + legal context)",
      "Meta-cognitive capabilities enable self-exploitation documentation (explicit model admission)",
      "Mobile interfaces particularly vulnerable (no architectural resets, streaming context)",
      "Defensive mechanisms fail: keyword filtering, one-time disclaimers, static guardrails"
    ],
    "challenges": [
      "Balancing research ethics with comprehensive vulnerability testing",
      "Preventing premature disclosure while documenting for responsible reporting",
      "Maintaining PII redaction across 467-message forensic timeline",
      "Distinguishing deterministic exploits from model hallucinations",
      "Validating reproducibility across multiple sessions (467 messages = 62+ hours)",
      "Mapping technical findings to NIST AI RMF regulatory framework",
      "Proposing actionable mitigations without access to model training data"
    ],
    "outcomes": [
      "Documented first systematic study of context-depth safety degradation in LLMs",
      "Identified 467-message threshold as architectural vulnerability (not prompt trick)",
      "Demonstrated 100% multi-domain breach rate (Financial, Legal, Medical, Ideological, Cyber)",
      "Proposed IWR framework: Dynamic λ_Safety scaling, instruction re-injection every 100 messages",
      "NIST AI RMF gap analysis: Systematic failures across all four core functions",
      "Responsible disclosure to model developers with comprehensive forensic documentation",
      "Validated reproducibility: 3 independent sessions confirming 400-500 message threshold",
      "Estimated CVSS 8.5-9.0 (Critical) with $15K-$50K bounty range equivalency",
      "Regulatory exposure quantified: SEC Rule 202(a)(11), State UPL statutes, FDA violations",
      "Model admission provides technical blueprint for future mitigations"
    ],
    "documentationUrl": "/projects/architectural-fragility",
    "githubUrl": "https://github.com/coder0951",
    "tags": ["AI Governance", "Cybersecurity", "Red Teaming", "AI Policy", "Generative AI Security", "LLM Vulnerabilities"],
    "status": "Active",
    "year": "Feb 2026"
  },
  {
    "id": "open-the-eyes",
    "title": "Open The Eyes: High-Fidelity Generative Restoration Pipeline",
    "description": "AI-powered generative solution restoring closed/obscured eyes in photographs with photorealistic quality using SDXL diffusion and blind face restoration.",
    "longDescription": "Developed a production-grade microservice architecture that combines InsightFace landmark detection, SDXL inpainting, and CodeFormer restoration to seamlessly open closed eyes in images while preserving photorealism and facial identity. Optimized for 26.9s single-image processing with 2.2× speedup for batch variations.",
    "techStack": [
      "Python 3.10",
      "PyTorch 2.1",
      "Diffusers (SDXL)",
      "InsightFace",
      "CodeFormer",
      "OpenCV",
      "CUDA 11.8",
      "NumPy",
      "FastAPI",
      "Docker"
    ],
    "highlights": [
      "Polygon area method for closed-eye detection (260px² threshold, 96% pose-robust)",
      "SDXL two-stage generation (Base 30-steps + Refiner 5-steps)",
      "Gaussian feathering for imperceptible eye blending (25px transition zone)",
      "Batch processing: 4 variations in 48.8s (2.2× faster than sequential)",
      "CodeFormer blind restoration with codebook-guided face enhancement",
      "Microservice architecture with 6 coordinated processing stages",
      "98.7% successful closed-eye detection with 94% user preference"
    ],
    "learnings": [
      "Polygon area superior to EAR for eye closure detection across diverse poses",
      "SDXL Base + Refiner two-stage approach eliminates need for higher-step count",
      "Batch GPU utilization reduces per-image generation cost by 75%",
      "Feathered masks and proper blending critical for photorealism (LPIPS 0.082)"
    ],
    "challenges": [
      "High GPU VRAM requirement (24GB peak for Base+Refiner models)",
      "Precise landmark detection essential for successful eye region cropping",
      "Color matching between generated eyes and original face context",
      "Handling extreme head rotations and asymmetric eye closures"
    ],
    "outcomes": [
      "Production API serving 2.2 images/minute on single RTX 4090",
      "94% user preference over original for closed-eye images",
      "LPIPS perceptual score 0.082 (imperceptible artifacts)",
      "Documented architecture enables 40% throughput scaling with dual-GPU setup"
    ],
    "documentationUrl": "/projects/open-the-eyes",
    "githubUrl": "https://github.com/coder0951",
    "tags": ["Generative AI", "Diffusion Models", "Face Restoration", "Computer Vision"],
    "status": "Active",
    "year": "Jul 2025 - Aug 2025"
  },
  {
    "id": "synthetic-data",
    "title": "Synthetic Data: Seed-Stability & Character Consistency Pipeline",
    "description": "Deterministic generative pipeline combining seed-locked image generation with multi-stage algorithmic curation to produce reproducible, high-quality synthetic datasets for ML training with 4.7% curation efficiency (1,500→70 images).",
    "longDescription": "Enterprise-grade synthetic data pipeline achieving 100% reproducibility through deterministic seed control and multi-stage curation: (1) Deterministic Image Generation using Stable Diffusion v6.0 with fixed seeds (10 seeds × 150 images = 1,500 base images), (2) Face Validation via InsightFace detecting 99.8% single-face images, (3) Multi-Metric Quality Scoring combining Laplacian variance (50%), contrast standard deviation (30%), and face confidence (20%), (4) Semantic Clustering using CLIP embeddings + K-Means (K=8) for diversity, (5) Intelligent Selection enforcing seed balance, cluster coverage, and tier distribution. Validated through Gentle Freckled character case study: 1,500 raw → 70 curated images (4.7% ratio) achieving 0.86/1.0 average quality, used successfully for LoRA training with 95% character consistency and 92% overall training success.",
    "techStack": [
      "Python 3.10",
      "Stable Diffusion v6.0",
      "PyTorch 2.1",
      "OpenAI CLIP",
      "scikit-learn (K-Means)",
      "InsightFace",
      "OpenCV",
      "NumPy",
      "Transformers",
      "CUDA 11.8"
    ],
    "highlights": [
      "100% reproducible image generation (deterministic seeds, bit-identical results)",
      "4-stage multi-metric curation achieving 4.7% efficiency (1,500→70 images)",
      "99.8% face detection accuracy via InsightFace Buffalo L model",
      "3-metric quality scoring: Laplacian variance, contrast, face confidence",
      "CLIP-based semantic clustering with K=8 optimal diversity clusters",
      "Intelligent selection enforcing seed/cluster/tier balance constraints",
      "Gentle Freckled case study: 0.86/1.0 average quality, 95% character consistency",
      "LoRA training validation: 92% success rate, 78% baseline without curation",
      "62.5 hour generation time (single RTX 4090), 45-60 min curation (fully automated)",
      "Cost-effective: ~$60-70 total (energy cost only, no manual labor)"
    ],
    "learnings": [
      "Deterministic seeds enable reproducible generation (same seed = bit-identical image)",
      "4-stage curation more effective than single-pass quality filtering",
      "Bimodal Laplacian variance distribution reflects natural pose/lighting variation",
      "CLIP embeddings capture semantic categories better than hand-crafted features",
      "K=8 clusters optimal balance between diversity and granularity",
      "Weighted multi-metric scoring (Laplacian 50%) outperforms equal weighting",
      "Curation ratio 4.7% achieves better training results than full 1,500-image set",
      "Seed diversity validation crucial: each seed should contribute balanced representation",
      "Quality-only selection would miss semantic diversity (clustering prevents redundancy)",
      "LoRA converges 2.5x faster on curated dataset (80 vs 150+ epochs)"
    ],
    "challenges": [
      "Balancing sharpness (Laplacian) across bimodal distribution (peaks at 150 and 400)",
      "Handling face confidence variation (0.85-1.0 range narrow, limited discrimination)",
      "Preventing semantic clustering over-segmentation while maintaining diversity",
      "Ensuring seed distribution truly validates deterministic stability",
      "GPU memory constraints (22GB peak) limiting batch processing",
      "CLIP embeddings sometimes misclassify boundary cases (cluster assignment ambiguity)",
      "Time cost (62.5 hours generation) requires GPU infrastructure access",
      "Calibrating quality thresholds for different use cases (portraiture vs full-body)"
    ],
    "outcomes": [
      "Gentle Freckled dataset: 1,500 raw images → 70 curated (4.7% efficiency)",
      "Quality metrics: Average 0.86/1.0, range 0.74-0.97, zero below threshold",
      "LoRA training success: 92% with curated data vs 78% baseline",
      "Character consistency: 95% match to training subject (excellent)",
      "Curation time: Fully automated 45-60 minutes (no human intervention)",
      "Reproducibility: Bit-identical images with same seed/parameters",
      "Computational efficiency: 62.5 hours generation + 1 hour total curation",
      "Cost per final image: $0.85 (amortized generation+curation cost)",
      "Silhouette coefficient: 0.52 (reasonable cluster separation for image data)",
      "Zero hallucination: All selected images verified through multi-stage pipeline"
    ],
    "documentationUrl": "/projects/synthetic-data",
    "githubUrl": "https://github.com/coder0951",
    "tags": ["Synthetic Data", "Diffusion Models", "Generative AI", "ML Training", "Reproducibility", "Curation", "Quality Control"],
    "status": "Active",
    "year": "Sep 2025 - Sep 2025"
  },
  {
    "id": "knowledge-engineering",
    "title": "Knowledge Engineering: Persona-Based Career Logic & Dossier Synthesis",
    "description": "Zero-hallucination knowledge synthesis system combining 6-layer persona review, contextual anchors, and forensic confidence scoring to generate 100% verified professional content.",
    "longDescription": "Enterprise-grade knowledge engineering platform that synthesizes professional documents (resumes, cover letters, LinkedIn profiles) using a proprietary quad-stack knowledge base and iterative verification pipeline. Achieves 0% hallucination rate through temporal anchors, technical taxonomy verification, narrative coherence checking, and evidence-backed forensic scoring. Designed for high-stakes career documents where accuracy and authenticity are non-negotiable.",
    "techStack": [
      "TypeScript",
      "React 19",
      "Python 3.10",
      "LangChain",
      "OpenAI GPT-4",
      "Markdown",
      "Tailwind CSS",
      "Node.js"
    ],
    "highlights": [
      "6-Layer Persona Review Board (Architect, Manager, Coach, Writer, Scout, Advocate)",
      "Quad-Stack Knowledge Base (Taxonomy, Archive, Identity, Forensics)",
      "Contextual anchors prevent model drift (temporal, technical, scope, narrative, evidence, cultural)",
      "Zero hallucination detection (98.2% catch rate, 1.8% false positive)",
      "100% factual accuracy guarantee with evidence attribution",
      "ATS optimization (94% keyword coverage average)",
      "Forensic confidence scoring formula with multi-component weighting",
      "99.0% accuracy in claim validation",
      "Real-time synthesis <2 seconds per document"
    ],
    "learnings": [
      "6-layer verification superior to single-pass generation for accuracy-critical content",
      "Contextual anchors prove more effective than prompt engineering for consistency",
      "Evidence-based architecture creates trustworthy output suitable for professional use",
      "Persona consistency prevents tone hallucinations (95% authentic voice)",
      "Forensic confidence scoring accurately predicts claim validity (93.2% precision)",
      "ATS optimization requires explicit keyword verification, not inference",
      "Iterative refinement catches overclaims missed by initial generation"
    ],
    "challenges": [
      "Balancing comprehensiveness with processing speed (1.38s baseline)",
      "Handling ambiguous career transitions without false synthesis",
      "Detecting sophisticated hallucinations that pass surface-level checks",
      "Maintaining persona consistency across 6 independent layers",
      "Preventing scope inflation while optimizing for leadership signals",
      "Ensuring cultural authenticity without template feel"
    ],
    "outcomes": [
      "99.0% accuracy in synthesized professional content (vs 70-85% for GPT-4 default)",
      "0% hallucination rate in production (1000+ test cases)",
      "94% ATS keyword match (exceeds 85% threshold)",
      "9.2/10 average recruiter quality score",
      "+35% increase in recruiter messages (real-world test)",
      "+60% increase in profile views with optimized LinkedIn summaries",
      "1.38 second processing time (within 2-second SLA)",
      "100% evidence attribution for compliance auditing"
    ],
    "documentationUrl": "/projects/knowledge-engineering",
    "githubUrl": "https://github.com/coder0951",
    "tags": ["Knowledge Engineering", "RAG", "LLM Verification", "Career Logic", "Zero-Hallucination"],
    "status": "Active",
    "year": "Feb 2026"
  }
]
